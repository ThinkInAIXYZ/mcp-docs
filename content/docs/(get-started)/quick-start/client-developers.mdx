---
title: 客户端开发者
description: 快速开始 - 客户端开发者
---
开始构建自己的客户端，可以与所有 MCP 服务器集成。

在本教程中，您将学习如何构建一个由 LLM 驱动、可连接 MCP 服务器的聊天机器人客户端。
而通过服务器快速入门Server quickstart可以帮助您完成构建第一个服务器的基本操作。

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
 

<Tabs items={['Python', 'Node', 'Java']}>
  <Tab value="Python">
本教程完整的代码在[这里](https://github.com/modelcontextprotocol/quickstart-resources/tree/main/mcp-client-python)
## 系统需求 ##
开始之前，确认你的系统满足如下需求：

- 操作系统Mac或Windows
- 安装了最新版本的Python
- 安装了最新版本的uv

## 设置环境 ##
首先，用uv新建一个Python项目:
```js
# Create project directory
uv init mcp-client
cd mcp-client

# Create virtual environment
uv venv

# Activate virtual environment
# On Windows:
.venv\Scripts\activate
# On Unix or MacOS:
source .venv/bin/activate

# Install required packages
uv add mcp anthropic python-dotenv

# Remove boilerplate files
rm hello.py

# Create our main file
touch client.py
```
## 安装你的API key ##

你需要从[Anthropic Console](https://console.anthropic.com/settings/keys)获取一个Anthropic API key
创建一个.env文件来存储它:
```js
# Create .env file
touch .env
```
将key添加到env文件
```js
ANTHROPIC_API_KEY=<your key here>
```
将env文件添加到你的.gitignore:
```js
echo ".env" >> .gitignore
```
<Callout title="Title" type="warn">
  请确保您的ANTHROPIC_API_KEY安全！
</Callout>
## 创建客户端 ##
### 客户端基础机构 ###
首先，我们设置import和创建基础的客户端类:
```js
import asyncio
from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from anthropic import Anthropic
from dotenv import load_dotenv

load_dotenv()  # load environment variables from .env

class MCPClient:
    def __init__(self):
        # Initialize session and client objects
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.anthropic = Anthropic()
    # methods will go here
```
### 服务器连接管理 ###
接下来，我们实现连接MCP服务器的方法:

```js
async def connect_to_server(self, server_script_path: str):
    """Connect to an MCP server

    Args:
        server_script_path: Path to the server script (.py or .js)
    """
    is_python = server_script_path.endswith('.py')
    is_js = server_script_path.endswith('.js')
    if not (is_python or is_js):
        raise ValueError("Server script must be a .py or .js file")

    command = "python" if is_python else "node"
    server_params = StdioServerParameters(
        command=command,
        args=[server_script_path],
        env=None
    )

    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
    self.stdio, self.write = stdio_transport
    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))

    await self.session.initialize()

    # List available tools
    response = await self.session.list_tools()
    tools = response.tools
    print("\nConnected to server with tools:", [tool.name for tool in tools])
```
### 查询处理的逻辑 ###
现在，现在让我们添加处理查询和工具调用的核心功能：
```js
async def process_query(self, query: str) -> str:
    """Process a query using Claude and available tools"""
    messages = [
        {
            "role": "user",
            "content": query
        }
    ]

    response = await self.session.list_tools()
    available_tools = [{
        "name": tool.name,
        "description": tool.description,
        "input_schema": tool.inputSchema
    } for tool in response.tools]

    # Initial Claude API call
    response = self.anthropic.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1000,
        messages=messages,
        tools=available_tools
    )

    # Process response and handle tool calls
    final_text = []

    assistant_message_content = []
    for content in response.content:
        if content.type == 'text':
            final_text.append(content.text)
            assistant_message_content.append(content)
        elif content.type == 'tool_use':
            tool_name = content.name
            tool_args = content.input

            # Execute tool call
            result = await self.session.call_tool(tool_name, tool_args)
            final_text.append(f"[Calling tool {tool_name} with args {tool_args}]")

            assistant_message_content.append(content)
            messages.append({
                "role": "assistant",
                "content": assistant_message_content
            })
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": content.id,
                        "content": result.content
                    }
                ]
            })

            # Get next response from Claude
            response = self.anthropic.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                messages=messages,
                tools=available_tools
            )

            final_text.append(response.content[0].text)

    return "\n".join(final_text)
```
### 和Chat进行交互 ###
现在我们添加一些chat来回交互和清理的功能：
```js
async def chat_loop(self):
    """Run an interactive chat loop"""
    print("\nMCP Client Started!")
    print("Type your queries or 'quit' to exit.")

    while True:
        try:
            query = input("\nQuery: ").strip()

            if query.lower() == 'quit':
                break

            response = await self.process_query(query)
            print("\n" + response)

        except Exception as e:
            print(f"\nError: {str(e)}")

async def cleanup(self):
    """Clean up resources"""
    await self.exit_stack.aclose()
```
### main函数入口要点 ###
最后，我们添加main入口执行逻辑
```js
async def main():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script>")
        sys.exit(1)

    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    import sys
    asyncio.run(main())
```
完整的client.py文件在这里
## 关键组件说明 ##
1. 客户端初始化 
- MCPClient类初始化会话管理和API客户端
- 使用AsyncExitStack进行适当的资源管理
- 为Claude交互配置Anthropic客户端
2. 服务器连接
- 支持Python和Node.js服务器
- 验证服务器脚本类型
- 建立适当的沟通通道
- 初始化会话并列出可用的工具
3. 查询处理
- 维护对话上下文
- 处理Claude的回复和工具调用
- 管理Claude和工具之间的消息流
- 将结果组合成连贯的回应
4. 交互界面
- 提供一个简单的命令行界面
- 处理用户输入并显示响应
- 包括基本错误处理
- 允许优雅退出
5. 资源管理
- 妥善清理资源
- 连接问题的错误处理
- 安全关机程序
## 通常的定制化要点 ##
1. 工具处理
- 修改process_query（）来处理特定的工具类型
- 为工具调用添加自定义错误处理
- 实现特定工具的响应格式
2. 响应处理
- 自定义工具结果的格式
- 添加响应过滤或转换
- 实现自定义日志记录
3. 用户界面
- 添加GUI或web界面
- 实现丰富的控制台输出
- 添加命令历史记录或自动完成
## 运行客户端 ##
运行客户端，可选择任意服务器：
```js
uv run client.py path/to/server.py # python server
uv run client.py path/to/build/index.js # node server
```
<Callout title="Title" type="info">
  如果你还在从服务器快速入门继续天气教程，你的命令可能看起来像这样：python client.py .../weather/src/weather/server.py
</Callout>
客户端将会：
1. 连接到指定的服务器
2. 列出可用的工具
3. 开始一个交互对话的会话，你可以实现以下操作：
- 输入查询
- 查看工具的执行情况
- 从Claude得到响应 

下面是一个在服务器快速入门教程中连接到天气服务器的示例：

![ImaImageZoomge](/client-claude-cli-python.png)
## 工作机制 ##
当你提交查询时：
1. 客户端从服务器获取可用工具的列表
2. 您的查询将与工具描述一起发送给Claude
3. Claude决定使用哪些工具（如果有的话）
4. 客户端通过服务器执行工具调用请求
5. 结果被送回给Claude
6. Claude用自然语言响应
7. 将返回的响应显示给用户
## 最佳实践 ##
1. 错误处理
- 始终将工具调用封装在try-catch块中
- 提供有意义的错误消息
- 优雅地处理连接问题
2. 资源管理
- 使用AsyncExitStack进行适当的清理
- 使用完成后关闭连接
- 处理服务器的连接断开
3. 安全性
- 将API key安全地存储在.env文件中
- 验证服务器响应
- 谨慎处理工具的使用权限
## 故障排除 ##
### 服务器路径问题 ###
- 再次检查服务器的路径是否正确
- 如果相对路径不起作用，请使用绝对路径
- 对于Windows用户，请确保在路径中使用正斜杠（/）或转义反斜杠（\）
- 验证服务器文件具有正确的扩展名（Python为.py或Node.js为.js）

正确的路径示例：
```js
# Relative path
uv run client.py ./server/weather.py

# Absolute path
uv run client.py /Users/username/projects/mcp-server/weather.py

# Windows path (either format works)
uv run client.py C:/projects/mcp-server/weather.py
uv run client.py C:\\projects\\mcp-server\\weather.py
```
### 响应时间 ### 
- 第一个响应可能需要30秒才能返回
- 这是正常的，发生在：
    - 服务器初始化
    - Claude处理查询
    - 工具正在执行
- 随后的反应通常更快
- 在最初的等待期间，不要中断该过程
### 常见错误信息 ###
当你看到：
- FileNotFoundError：检查你的服务器路径
- Connection refused：确认服务器在运行并且路径正确
- Tool execution failed：验证工具所需的环境变量是否已设置
- Timeout error：考虑在客户端配置中增加超时

</Tab>
  <Tab value="Node">Rust is fast</Tab>
  <Tab value="Java">Rust is fast</Tab>
</Tabs>
