---
title: 介绍
description: 开始使用模型上下文协议 (MCP)
---

MCP 是一个开放协议，使LLM应用，就如何向大型语言模型 (LLM) 提供上下文，实现统一。可以将 MCP 想象成 AI 应用程序的 USB-C 接口。就像 USB-C 提供了一种标准化的方式来连接设备跟各种外设一样，MCP 提供了一种标准化的方式来连接 AI 模型与不同的数据源和工具。

## 为什么选择 MCP？

MCP 帮助你在 LLM 之上构建代理和复杂的工作流。LLM 经常需要与数据和工具集成，而 MCP 提供了：

- 已构建的集成应用在不断增加，你的LLM可以直接接入
- 在 LLM 提供者及供应商之间灵活地切换
- 在你的基础设施内实现数据安全的最佳实践

### 总体架构

MCP 的核心遵循客户端-服务器架构，其中主机可以连接到多个服务器：

- **MCP 主机**：像 Claude 桌面版、IDEs 或 AI 工具等，想要通过 MCP 访问数据的程序
- **MCP 客户端**：协议的客户端，与服务器保持1:1的连接
- **MCP 服务器**：轻量级程序，通过标准的模型上下文协议暴露特定功能
- **本地数据源**：你的电脑上的文件、数据库和服务等MCP 服务器可以安全访问的资源
- **远程服务**：MCP 服务器可通过互联网（如 API）连接的外部系统
